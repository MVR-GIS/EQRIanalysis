[
  {
    "objectID": "03_factor_analysis.html",
    "href": "03_factor_analysis.html",
    "title": "Factor Analysis",
    "section": "",
    "text": "Factor analysis evaluates the underlying structure of the EQRI questionnaire to answer:\n\nAre we asking the right questions? (coverage, gaps, redundancy)\nHow many dimensions? Do questions measure distinct aspects of engineering quality?\nQuestion sensitivity: Which questions most influence each indicator?"
  },
  {
    "objectID": "03_factor_analysis.html#overview",
    "href": "03_factor_analysis.html#overview",
    "title": "Factor Analysis",
    "section": "",
    "text": "Factor analysis evaluates the underlying structure of the EQRI questionnaire to answer:\n\nAre we asking the right questions? (coverage, gaps, redundancy)\nHow many dimensions? Do questions measure distinct aspects of engineering quality?\nQuestion sensitivity: Which questions most influence each indicator?"
  },
  {
    "objectID": "03_factor_analysis.html#analysis-strategy",
    "href": "03_factor_analysis.html#analysis-strategy",
    "title": "Factor Analysis",
    "section": "Analysis Strategy",
    "text": "Analysis Strategy\nPer Little & Rubin (2019, Statistical Analysis with Missing Data), questionnaires with structural missingness by design require context-aware analysis.\nThe EQRI questionnaire includes:\n\nCore items: Asked across most/all contexts (program types × milestones)\nContext-specific items: Asked only for certain programs or milestones\n\n\nApproach\nBased on the revised factor analysis strategy (see dev/revised_sprint1_strategy.R):\n\nIdentify core items - Questions present in ≥8 of 10 contexts (&lt;20% missing)\nAssess factorability by context - Evaluate each program × milestone combination\nDocument response patterns - Show which contexts have sufficient data for analysis\n\n\n\nQuestion Coverage Visualization\nThis heatmap shows which questions are asked in each context, helping identify core vs. context-specific items.\n\n\n\n\n\nQuestion coverage across program types and milestones\n\n\n\n\nReading the heatmap:\n\nDark blue cells: Question asked in that context\nLight gray cells: Question not asked (structural missingness by design)\nCore items (top panel): Asked broadly across contexts\nContext-specific items (bottom panel): Asked selectively for certain programs/milestones"
  },
  {
    "objectID": "03_factor_analysis.html#step-1-identify-core-items",
    "href": "03_factor_analysis.html#step-1-identify-core-items",
    "title": "Factor Analysis",
    "section": "Step 1: Identify Core Items",
    "text": "Step 1: Identify Core Items\nPer Schafer & Graham (2002), items with &lt;20% missing data are suitable for aggregated analysis.\n\nCore Items Summary\nTotal questions in questionnaire: 38\nCore items (≥ 8 of 10 contexts): 27\nContext-specific items (&lt; 8 of 10 contexts): 11\nPer Schafer & Graham (2002), focusing on core items for factor analysis is appropriate when items exhibit structural missingness by design."
  },
  {
    "objectID": "03_factor_analysis.html#step-2-questionnaire-response-rates",
    "href": "03_factor_analysis.html#step-2-questionnaire-response-rates",
    "title": "Factor Analysis",
    "section": "Step 2: Questionnaire Response Rates",
    "text": "Step 2: Questionnaire Response Rates\nUnderstanding response patterns by context helps identify which contexts have sufficient data for factor analysis.\n\nTotal Contexts\nProgram types: 2 (Military, Civil Works)\nMilestones: 5\nTotal contexts (program × milestone): 10\n\n\nResponse Rates by Context\n\n\n\nQuestionnaire Events and Responses by Context\n\n\nProgram Type\nMilestone\nEvents\nResponses\n\n\n\n\nCivil Works\n15% (Project Initiation)\n38\n1102\n\n\nCivil Works\n35% (Concept Design)\n26\n988\n\n\nCivil Works\n65% (Intermediate Design)\n32\n1312\n\n\nCivil Works\n95% (Final Design)\n18\n721\n\n\nCivil Works\n100% (Corrected Final Design)\n17\n493\n\n\nMilitary\n15% (Project Initiation)\n30\n810\n\n\nMilitary\n35% (Concept Design)\n51\n1938\n\n\nMilitary\n65% (Intermediate Design)\n37\n1480\n\n\nMilitary\n95% (Final Design)\n41\n1599\n\n\nMilitary\n100% (Corrected Final Design)\n52\n1456\n\n\n\n\n\nEvents: Number of unique questionnaire submissions (one per project at each milestone)\nResponses: Total individual question responses (events × questions asked in that context)"
  },
  {
    "objectID": "03_factor_analysis.html#step-3-question-coverage-across-contexts",
    "href": "03_factor_analysis.html#step-3-question-coverage-across-contexts",
    "title": "Factor Analysis",
    "section": "Step 3: Question Coverage Across Contexts",
    "text": "Step 3: Question Coverage Across Contexts\nThis table shows which questions are “core” (broadly applicable) vs. context-specific.\n\n\n\nQuestion Coverage: Core vs. Context-Specific Items\n\n\nQuestion\nType\n# Contexts\nTotal Responses\n% Missing\n\n\n\n\n1\nCore\n10\n342\n97.1\n\n\n2\nCore\n10\n342\n97.1\n\n\n3\nCore\n10\n1026\n91.4\n\n\n5\nCore\n10\n342\n97.1\n\n\n6\nCore\n10\n342\n97.1\n\n\n7\nCore\n10\n342\n97.1\n\n\n8\nCore\n10\n342\n97.1\n\n\n13\nCore\n10\n342\n97.1\n\n\n20\nCore\n10\n342\n97.1\n\n\n34\nCore\n10\n342\n97.1\n\n\n38\nCore\n10\n342\n97.1\n\n\n12\nCore\n8\n819\n93.1\n\n\n15\nCore\n8\n273\n97.7\n\n\n16\nCore\n8\n273\n97.7\n\n\n17\nCore\n8\n819\n93.1\n\n\n18\nCore\n8\n273\n97.7\n\n\n19\nCore\n8\n273\n97.7\n\n\n22\nCore\n8\n274\n97.7\n\n\n23\nCore\n8\n548\n95.4\n\n\n24\nCore\n8\n274\n97.7\n\n\n25\nCore\n8\n274\n97.7\n\n\n27\nCore\n8\n274\n97.7\n\n\n28\nCore\n8\n274\n97.7\n\n\n31\nCore\n8\n274\n97.7\n\n\n32\nCore\n8\n274\n97.7\n\n\n33\nCore\n8\n274\n97.7\n\n\n37\nCore\n8\n274\n97.7\n\n\n4\nContext-specific\n7\n215\n98.2\n\n\n21\nContext-specific\n6\n410\n96.6\n\n\n26\nContext-specific\n6\n197\n98.3\n\n\n30\nContext-specific\n6\n394\n96.7\n\n\n11\nContext-specific\n5\n131\n98.9\n\n\n9\nContext-specific\n2\n68\n99.4\n\n\n14\nContext-specific\n2\n68\n99.4\n\n\n29\nContext-specific\n2\n69\n99.4\n\n\n10\nContext-specific\n1\n76\n99.4\n\n\n35\nContext-specific\n1\n51\n99.6\n\n\n36\nContext-specific\n1\n30\n99.7\n\n\n\n\n\nInterpretation:\n\nCore items (≥8 contexts): Analyzed across contexts\nContext-specific items (&lt;8 contexts): Analyzed only within their relevant contexts"
  },
  {
    "objectID": "03_factor_analysis.html#step-4-factorability-by-context",
    "href": "03_factor_analysis.html#step-4-factorability-by-context",
    "title": "Factor Analysis",
    "section": "Step 4: Factorability by Context",
    "text": "Step 4: Factorability by Context\nDue to data characteristics (varying response patterns, context-specific items), we assess factorability for the contexts with the most data.\n\nContexts Selected for Analysis\nBased on response rates, we focus on the four largest contexts:\n\nMilitary × 100% (Corrected Final Design) - 52 events\nMilitary × 35% (Concept Design) - 51 events\nMilitary × 95% (Final Design) - 41 events\nCivil Works × 15% (Project Initiation) - 38 events\n\n\n\n\n\n\n\nWhy Context-Specific Analysis?\n\n\n\nPer Little & Rubin (2019), aggregating across contexts with structural missingness can produce misleading results. Analyzing within contexts ensures:\n\nOnly applicable questions are included\nResponse patterns are interpretable\nSufficient variability for correlation analysis\n\n\n\n\n\n\nMilitary × 95% (Final Design)\n\nSample Size\nComplete cases: 41\nItems analyzed: 3\n\n\nAssessment\n✅ Suitable for factor analysis\nRationale: Sample size below recommended N=100 minimum\n\n\n\n\nCivil Works × 95% (Final Design)\n\nSample Size\nComplete cases: 18\nItems analyzed: 7\n\n\nAssessment\n✅ Suitable for factor analysis\nRationale: Sample size below recommended N=100 minimum\n\n\n\n\nAdditional Contexts\n\n\nMilitary × 95% (Final Design)\nComplete cases: 41 | Items analyzed: 3\n✅ Suitable for factor analysis\nRationale: Sample size below recommended N=100 minimum\n\n\nCivil Works × 15% (Project Initiation)\nComplete cases: 38 | Items analyzed: 5\n✅ Suitable for factor analysis\nRationale: Sample size below recommended N=100 minimum"
  },
  {
    "objectID": "03_factor_analysis.html#summary-interpretation",
    "href": "03_factor_analysis.html#summary-interpretation",
    "title": "Factor Analysis",
    "section": "Summary & Interpretation",
    "text": "Summary & Interpretation\n\nData Characteristics Observed\nQuestionnaire composition:\n\nCore items: 27 (71.1%)\nContext-specific items: 11 (28.9%)\n\nImplication: The questionnaire is highly tailored to specific contexts, which is appropriate for capturing milestone- and program-specific quality factors.\n\n\nRecommendations\nBased on the factorability assessments:\n\nFor contexts with sufficient data:\n\nProceed with parallel analysis to determine number of factors\nConduct exploratory factor analysis (EFA)\nExamine factor loadings to interpret question groupings\n\nFor contexts with insufficient data:\n\nContinue data collection\nConsider aggregating across similar milestones (e.g., early vs. late design phases)\nFocus on descriptive statistics until sample size increases\n\nContext-specific items:\n\nValuable for targeted quality assessment within their domains\nShould not be removed - they serve important context-specific purposes\nWill be analyzed separately as data accrues"
  },
  {
    "objectID": "03_factor_analysis.html#next-steps",
    "href": "03_factor_analysis.html#next-steps",
    "title": "Factor Analysis",
    "section": "Next Steps",
    "text": "Next Steps\nImmediate: 1. Review factorability results with subject matter experts 2. For viable contexts, run parallel analysis to determine optimal factor structure 3. Conduct EFA on contexts meeting psychometric requirements\nFuture: 1. As data accrues, reassess contexts with currently insufficient samples 2. Investigate whether context-specific items cluster into meaningful factors within their domains 3. Test measurement invariance on core items across contexts (Phase 4)"
  },
  {
    "objectID": "03_factor_analysis.html#references",
    "href": "03_factor_analysis.html#references",
    "title": "Factor Analysis",
    "section": "References",
    "text": "References\n\nFlora, D. B., & Curran, P. J. (2004). An empirical evaluation of alternative methods of estimation for confirmatory factor analysis with ordinal data. Psychological Methods, 9(4), 466-491. https://doi.org/10.1037/1082-989X.9.4.466\nLittle, R. J. A., & Rubin, D. B. (2019). Statistical Analysis with Missing Data (3rd ed.). Wiley. Chapter 1.4.3: Structural missingness by design.\nSchafer, J. L., & Graham, J. W. (2002). Missing data: Our view of the state of the art. Psychological Methods, 7(2), 147-177. https://doi.org/10.1037/1076-8986.7.2.147"
  },
  {
    "objectID": "03_factor_analysis.html#question-to-indicator-mapping",
    "href": "03_factor_analysis.html#question-to-indicator-mapping",
    "title": "Factor Analysis",
    "section": "Question-to-Indicator Mapping",
    "text": "Question-to-Indicator Mapping\nUnderstanding which questions contribute to each indicator is essential for interpreting indicator scores and conducting factor analysis.\n\nVisual Mapping\n\n\n\n\n\nQuestions mapped to EQRI indicators\n\n\n\n\nReading the visualization:\n\nBlue cells: Question contributes to this indicator\nGray cells: Question does not contribute to this indicator\nQuestions are grouped by their assigned indicator for easy interpretation\n\n\n\nSummary Table\n\n\n\nNumber of questions per indicator\n\n\n\n\n\n\n\n\nIndicator\nQuestions\nResponses\nQuestion Numbers\n\n\n\n\nConfidence\n1\n342\n38\n\n\nCost\n6\n797\n10, 11, 12, 33, 35, 36\n\n\nQA\n8\n1976\n3, 17, 21, 23, 29, 30, 32, 34\n\n\nQC\n11\n2858\n3, 17, 21, 22, 23, 24, 25, 26, 27, 28, 30\n\n\nSchedule\n7\n1980\n12, 15, 16, 17, 18, 19, 20\n\n\nScope\n6\n1063\n9, 10, 12, 13, 14, 31\n\n\nTeam\n9\n2883\n1, 2, 3, 4, 5, 6, 7, 8, 37\n\n\n\n\n\nInterpretation:\nThe seven EQRI indicators are calculated from specific sets of questions:\n\nConfidence: 1 questions (38)\nCost: 6 questions (10, 11, 12, 33, 35, 36)\nQA: 8 questions (3, 17, 21, 23, 29, 30, 32, 34)\nQC: 11 questions (3, 17, 21, 22, 23, 24, 25, 26, 27, 28, 30)\nSchedule: 7 questions (12, 15, 16, 17, 18, 19, 20)\nScope: 6 questions (9, 10, 12, 13, 14, 31)\nTeam: 9 questions (1, 2, 3, 4, 5, 6, 7, 8, 37)\n\nThis mapping is defined in the questionnaire design and determines how individual question responses aggregate into indicator scores."
  }
]